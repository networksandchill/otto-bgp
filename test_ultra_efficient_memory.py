#!/usr/bin/env python3
"""
Ultra-efficient memory optimization test
Tests the new ultra-efficient streaming mode for maximum memory reduction
"""

import logging
import sys
import os
import tempfile
import gc
from pathlib import Path

# Add the project root to Python path
sys.path.insert(0, str(Path(__file__).parent))

from otto_bgp.processors.as_extractor import ASNumberExtractor

# Set up logging with minimal verbosity
logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_large_bgp_file(file_path: Path, size_mb: int) -> Path:
    """Create a large BGP configuration file for testing"""
    print(f"Creating {size_mb}MB BGP test file...")
    
    # Calculate lines needed for target size
    avg_line_length = 60  # bytes per line
    target_bytes = size_mb * 1024 * 1024
    target_lines = target_bytes // avg_line_length
    
    as_number = 10000
    
    with open(file_path, 'w', encoding='utf-8') as f:
        for i in range(target_lines):
            if i % 20 == 0:  # Every 20th line has an AS number
                line = f"neighbor 10.{(i//65536)%256}.{(i//256)%256}.{i%256} {{ peer-as {as_number}; }}\n"
                as_number += 1
                if as_number > 65000:  # Wrap around to avoid reserved ranges
                    as_number = 10000
            else:
                # Filler lines with varying content
                line = f"interface ge-{i//1000}/{(i//100)%10}/{i%100} {{ description \"Port {i}\"; mtu 9000; }}\n"
            
            f.write(line)
    
    actual_size = file_path.stat().st_size / 1024 / 1024
    print(f"Created {actual_size:.1f}MB file with ~{target_lines//20} AS numbers")
    
    return file_path


def measure_memory_usage(extractor, file_path, method_name):
    """Measure memory usage for extraction method"""
    
    # Force garbage collection before measurement
    gc.collect()
    
    # Get initial memory state
    try:
        import psutil
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024  # MB
        memory_monitoring = True
    except ImportError:
        memory_before = 0
        memory_monitoring = False
        print("‚ö† psutil not available - install with: pip install psutil")
    
    # Run extraction
    import time
    start_time = time.time()
    
    try:
        result = extractor.extract_as_numbers_from_file(file_path)
        success = True
        as_count = len(result.as_numbers)
        extraction_method = result.extraction_method
        error = None
    except Exception as e:
        success = False
        as_count = 0
        extraction_method = "failed"
        error = str(e)
    
    end_time = time.time()
    
    # Get final memory state
    if memory_monitoring:
        try:
            memory_after = process.memory_info().rss / 1024 / 1024  # MB
        except:
            memory_after = memory_before
    else:
        memory_after = memory_before
    
    return {
        "method": method_name,
        "extraction_method": extraction_method,
        "success": success,
        "as_count": as_count,
        "processing_time": end_time - start_time,
        "memory_before_mb": memory_before,
        "memory_after_mb": memory_after,
        "memory_delta_mb": memory_after - memory_before,
        "memory_monitoring": memory_monitoring,
        "error": error
    }


def test_ultra_efficient_memory_optimization():
    """Test ultra-efficient memory optimization with large files"""
    
    test_file_size = 50  # MB
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as temp_file:
        test_file = Path(temp_file.name)
    
    try:
        # Create large test file
        create_large_bgp_file(test_file, test_file_size)
        
        print(f"\nTesting memory usage with {test_file_size}MB file...")
        print("=" * 60)
        
        # Test 1: Legacy method
        print("1. Testing Legacy method...")
        extractor_legacy = ASNumberExtractor(
            enable_streaming=False,
            warn_reserved=False
        )
        
        legacy_results = measure_memory_usage(extractor_legacy, test_file, "Legacy")
        del extractor_legacy
        gc.collect()
        
        # Test 2: Standard streaming method
        print("2. Testing Standard streaming method...")
        extractor_streaming = ASNumberExtractor(
            enable_streaming=True,
            ultra_efficient_mode=False,
            warn_reserved=False,
            streaming_memory_limit_mb=10  # Conservative limit
        )
        
        streaming_results = measure_memory_usage(extractor_streaming, test_file, "Streaming")
        del extractor_streaming
        gc.collect()
        
        # Test 3: Ultra-efficient method
        print("3. Testing Ultra-efficient method...")
        extractor_ultra = ASNumberExtractor(
            enable_streaming=True,
            ultra_efficient_mode=True,
            warn_reserved=False,
            streaming_memory_limit_mb=5  # Very conservative limit
        )
        
        ultra_results = measure_memory_usage(extractor_ultra, test_file, "Ultra-Efficient")
        del extractor_ultra
        gc.collect()
        
        # Report results
        print("\n" + "="*80)
        print(f"ULTRA-EFFICIENT MEMORY OPTIMIZATION TEST RESULTS ({test_file_size}MB file)")
        print("="*80)
        
        results_list = [legacy_results, streaming_results, ultra_results]
        
        for results in results_list:
            print(f"\n{results['method']} Method ({results['extraction_method']}):")
            if results['success']:
                print(f"  Processing time: {results['processing_time']:.2f}s")
                if results['memory_monitoring']:
                    print(f"  Memory before:   {results['memory_before_mb']:.1f}MB")
                    print(f"  Memory after:    {results['memory_after_mb']:.1f}MB")
                    print(f"  Memory delta:    {results['memory_delta_mb']:.1f}MB")
                else:
                    print(f"  Memory monitoring: Not available")
                print(f"  AS numbers found: {results['as_count']}")
            else:
                print(f"  ERROR: {results['error']}")
        
        # Calculate improvements
        if all(r['success'] for r in results_list) and legacy_results['memory_monitoring']:
            legacy_peak = legacy_results['memory_after_mb']
            streaming_peak = streaming_results['memory_after_mb']
            ultra_peak = ultra_results['memory_after_mb']
            
            streaming_reduction = ((legacy_peak - streaming_peak) / legacy_peak) * 100 if legacy_peak > 0 else 0
            ultra_reduction = ((legacy_peak - ultra_peak) / legacy_peak) * 100 if legacy_peak > 0 else 0
            
            print(f"\nMEMORY OPTIMIZATION SUMMARY:")
            print(f"  Legacy peak memory:        {legacy_peak:.1f}MB")
            print(f"  Streaming peak memory:     {streaming_peak:.1f}MB")
            print(f"  Ultra-efficient peak:      {ultra_peak:.1f}MB")
            print(f"  Streaming reduction:       {streaming_reduction:.1f}%")
            print(f"  Ultra-efficient reduction: {ultra_reduction:.1f}%")
            
            # Check accuracy
            legacy_count = legacy_results['as_count']
            streaming_count = streaming_results['as_count']
            ultra_count = ultra_results['as_count']
            
            if legacy_count == streaming_count == ultra_count:
                print(f"  Accuracy check:            ‚úì PASS (all methods identical)")
            else:
                print(f"  Accuracy check:            ‚úó FAIL (counts differ)")
                print(f"    Legacy: {legacy_count}, Streaming: {streaming_count}, Ultra: {ultra_count}")
            
            # Determine success
            if ultra_reduction >= 50:  # Target: 50-70% reduction
                print(f"  Result:                    ‚úì SUCCESS - Target memory reduction achieved!")
                return True
            elif ultra_reduction >= 30:
                print(f"  Result:                    ‚úì GOOD - Significant memory reduction achieved")
                return True
            elif ultra_reduction >= 10:
                print(f"  Result:                    ‚ö† MARGINAL - Some improvement but below target")
                return False
            else:
                print(f"  Result:                    ‚úó FAILED - Minimal or no improvement")
                return False
        else:
            print(f"  Result:                    ‚úó UNABLE TO MEASURE - Missing data or failures")
            return False
    
    except Exception as e:
        print(f"Test failed with error: {e}")
        return False
    
    finally:
        # Clean up test file
        try:
            os.unlink(test_file)
        except OSError:
            pass


def test_size_scaling():
    """Test memory optimization across different file sizes"""
    
    test_sizes = [25, 50, 75, 100]  # MB
    print(f"\nTesting ultra-efficient mode scaling across file sizes...")
    print("="*80)
    
    print(f"{'Size':>6} {'Legacy':>8} {'Ultra':>8} {'Reduction':>10} {'Legacy T':>9} {'Ultra T':>9}")
    print(f"{'(MB)':>6} {'(MB)':>8} {'(MB)':>8} {'(%)':>10} {'(sec)':>9} {'(sec)':>9}")
    print("-" * 60)
    
    successful_tests = 0
    
    for size_mb in test_sizes:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as temp_file:
            test_file = Path(temp_file.name)
        
        try:
            # Create test file
            create_large_bgp_file(test_file, size_mb)
            
            # Test legacy method
            extractor_legacy = ASNumberExtractor(enable_streaming=False, warn_reserved=False)
            legacy_results = measure_memory_usage(extractor_legacy, test_file, f"Legacy-{size_mb}MB")
            del extractor_legacy
            gc.collect()
            
            # Test ultra-efficient method
            extractor_ultra = ASNumberExtractor(
                enable_streaming=True, 
                ultra_efficient_mode=True, 
                warn_reserved=False,
                streaming_memory_limit_mb=5
            )
            ultra_results = measure_memory_usage(extractor_ultra, test_file, f"Ultra-{size_mb}MB")
            del extractor_ultra
            gc.collect()
            
            # Calculate metrics
            if (legacy_results['success'] and ultra_results['success'] and 
                legacy_results['memory_monitoring']):
                
                memory_reduction = ((legacy_results['memory_after_mb'] - ultra_results['memory_after_mb']) / 
                                  legacy_results['memory_after_mb']) * 100 if legacy_results['memory_after_mb'] > 0 else 0
                
                print(f"{size_mb:>6} {legacy_results['memory_after_mb']:>8.1f} {ultra_results['memory_after_mb']:>8.1f} "
                      f"{memory_reduction:>10.1f} {legacy_results['processing_time']:>9.2f} {ultra_results['processing_time']:>9.2f}")
                
                if memory_reduction >= 30:  # At least 30% reduction
                    successful_tests += 1
            else:
                print(f"{size_mb:>6} {'ERROR':>8} {'ERROR':>8} {'N/A':>10} {'N/A':>9} {'N/A':>9}")
        
        except Exception as e:
            print(f"{size_mb:>6} {'ERROR':>8} {'ERROR':>8} {'N/A':>10} {'N/A':>9} {'N/A':>9}")
            logger.error(f"Error testing {size_mb}MB file: {e}")
        
        finally:
            try:
                os.unlink(test_file)
            except OSError:
                pass
    
    print(f"\nSuccessful tests (‚â•30% reduction): {successful_tests}/{len(test_sizes)}")
    return successful_tests >= len(test_sizes) // 2


def main():
    """Run ultra-efficient memory optimization tests"""
    
    print("Otto BGP Ultra-Efficient Memory Optimization Test")
    print("This test validates the new ultra-efficient streaming mode")
    print("Target: 50-70% memory reduction for large BGP configuration files")
    
    # Check if psutil is available
    try:
        import psutil
        print(f"‚úì Memory monitoring available (psutil installed)")
    except ImportError:
        print(f"‚ö† Limited memory monitoring - install psutil for detailed metrics:")
        print(f"  pip install psutil")
    
    # Run tests
    test1_passed = test_ultra_efficient_memory_optimization()
    test2_passed = test_size_scaling()
    
    print("\n" + "="*80)
    print("FINAL ULTRA-EFFICIENT TEST RESULTS:")
    print("="*80)
    
    if test1_passed and test2_passed:
        print("üéâ EXCELLENT: Ultra-efficient streaming optimization is working perfectly!")
        print("   ‚úì Target 50-70% memory reduction achieved")
        print("   ‚úì Processing accuracy maintained across all methods")
        print("   ‚úì Scalability confirmed across different file sizes")
        print("   ‚úì Auto-detection and configuration working correctly")
        return 0
    elif test1_passed or test2_passed:
        print("‚úÖ GOOD: Significant memory optimization achieved")
        print("   ‚úì Ultra-efficient mode providing substantial memory savings")
        print("   - Some room for improvement in edge cases")
        return 0
    else:
        print("‚ùå NEEDS IMPROVEMENT: Ultra-efficient optimization below expectations")
        print("   - Review ultra-efficient implementation")
        print("   - Consider additional memory management strategies")
        return 1


if __name__ == "__main__":
    sys.exit(main())